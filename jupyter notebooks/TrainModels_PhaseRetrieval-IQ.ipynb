{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Conv1DTranspose, Conv1D, Flatten, Add, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from commpy.modulation import QAMModem\n",
    "\n",
    "from optic.dsp import pulseShape, firFilter, decimate, symbolSync, resample\n",
    "from optic.models import phaseNoise, linFiberCh, KramersKronigRx, photodiode\n",
    "\n",
    "from optic.tx import simpleWDMTx\n",
    "from optic.core import parameters\n",
    "from optic.equalization import edc, mimoAdaptEqualizer\n",
    "from optic.carrierRecovery import cpr\n",
    "from optic.metrics import fastBERcalc, monteCarloGMI, monteCarloMI, signal_power\n",
    "from optic.plot import pconst\n",
    "\n",
    "import scipy.constants as const\n",
    "from tqdm.notebook import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path(r'C:/Users/silas/Documents/PIVIC-PIBIC-Comunicacoes-Opticas/models/deep_tcn_tensorflow').parent.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.deep_tcn_tensorflow.model import DeepTCN\n",
    "from models.deep_tcn_tensorflow.plots import plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares para permutar o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutate_input_output(input_matrix, output_matrix):\n",
    "    \n",
    "    num_rows, num_cols = input_matrix.shape\n",
    "    # Cria uma matriz de permutação para trocar as linhas\n",
    "    permutation = np.random.permutation(num_rows)\n",
    "\n",
    "    # Aplica a permutação nas matrizes de entrada e saída\n",
    "    permuted_input_matrix = input_matrix[permutation]\n",
    "    permuted_output_matrix = output_matrix[permutation]\n",
    "\n",
    "    return permuted_input_matrix, permuted_output_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dataset(X_train, y_train):\n",
    "  \"\"\"\n",
    "  Embaralha os dados de treinamento X_train e y_train.\n",
    "\n",
    "  Args:\n",
    "    X_train: Conjunto de dados de treinamento.\n",
    "    y_train: Rótulos de treinamento.\n",
    "\n",
    "  Returns:\n",
    "    X_train, y_train: Conjunto de dados e rótulos embaralhados.\n",
    "  \"\"\"\n",
    "\n",
    "  # Obtém o número de amostras.\n",
    "  n_samples = X_train.shape[0]\n",
    "\n",
    "  # Cria uma lista de índices aleatórios.\n",
    "  shuffled_indices = np.random.permutation(n_samples)\n",
    "\n",
    "  # Embala os dados e os rótulos de acordo com os índices aleatórios.\n",
    "  X_train_shuffled = X_train[shuffled_indices]\n",
    "  y_train_shuffled = y_train[shuffled_indices]\n",
    "\n",
    "  return X_train_shuffled, y_train_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a rede convolucional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convnet(N, n0, img_path='convnet_image.png'):\n",
    "    \n",
    "    \"\"\" Esta função retorna o modelo da rede neural citada pelo artigo \n",
    "    \"Deep learning-based Phase Retrieval Scheme for Minimum-phase Signal Recovery\".\n",
    "    Alguns parâmetros podem ser fixos como:\n",
    "    \n",
    "    k = 3: tamanho do kernel das camadas convolucionais 1D dentro de um Bloco D/U\n",
    "    s: passo das camadas convolucionais 1D dentro de um bloco D/U, para este caso foi selecionado s = 2.\n",
    "    d: profundidade do modelo, ou seja, o número de blocos D e U, para este caso foi selecionado d = 3\n",
    "        \n",
    "    Args:\n",
    "        N (int): Número de amostras de amplitude do sinal.\n",
    "        n0 (int): Número de núcleos de camadas convolucionais 1D dentro de um bloco D/U\n",
    "        img_path (str, optional): Nome do arquivo de saída para o plot do modelo em .png. Defaults to 'convnet_image.png'.\n",
    "\n",
    "    Returns:\n",
    "        object: modelo da rede neural.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()   \n",
    "    input_shape = tf.keras.Input(shape=(N, 1))\n",
    "    \n",
    "    normalize = BatchNormalization()(input_shape)\n",
    "    relu_layer = Activation('relu')(normalize)\n",
    "\n",
    "    # skip connection\n",
    "    skipConnection0 = Conv1D(filters=n0, kernel_size=1, activation='linear')(relu_layer)\n",
    "    \n",
    "    ## D Block 01\n",
    "    Dtower_7 = Conv1D(n0, kernel_size=3, padding='same', strides=2, activation='relu')(relu_layer)\n",
    "    # parallel layer\n",
    "    Dtower_parallel_01 = Conv1D(n0, kernel_size=3, padding='same', strides=2, activation='relu')(relu_layer)\n",
    "    Dtower_8 = Conv1D(n0, kernel_size=3, padding='same', activation='relu')(Dtower_7)\n",
    "    D01_added = Add()([Dtower_8, Dtower_parallel_01])\n",
    "     \n",
    "    # skip connection\n",
    "    skipConnection1 = Conv1D(filters=n0, kernel_size=1, activation='linear')(D01_added)\n",
    "    \n",
    "    ## D Block 02\n",
    "    Dtower_5 = Conv1D(n0, kernel_size=3, padding='same', strides=2, activation='relu')(D01_added)\n",
    "    # parallel layer\n",
    "    Dtower_parallel_02 = Conv1D(n0, kernel_size=3, padding='same', strides=2, activation='relu')(D01_added)  \n",
    "    Dtower_6 = Conv1D(n0, kernel_size=3, padding='same', activation='relu')(Dtower_5)\n",
    "    D02_added = Add()([Dtower_6, Dtower_parallel_02])\n",
    "    \n",
    "    # skip connection\n",
    "    skipConnection2 = Conv1D(filters=n0, kernel_size=1, activation='linear')(D02_added)\n",
    "    \n",
    "    ## D Block 03\n",
    "    Dtower_3 = Conv1D(n0, kernel_size=3, padding='same', strides=2, activation='relu')(D02_added)\n",
    "    # parallel layer\n",
    "    Dtower_parallel_03 = Conv1D(n0, kernel_size=3, padding='same', strides=2, activation='relu')(D02_added)  \n",
    "    Dtower_4 = Conv1D(n0, kernel_size=3, padding='same', activation='relu')(Dtower_3)\n",
    "    D03_added = Add()([Dtower_4, Dtower_parallel_03])\n",
    "\n",
    "    ## U Block 03 \n",
    "    tower_1 = Conv1DTranspose(n0, kernel_size=3, padding='same', strides=2, activation='relu')(D03_added)\n",
    "    # parallel layer\n",
    "    tower_parallel_03 = Conv1DTranspose(n0, kernel_size=3, padding='same', strides=2, activation='relu')(D03_added)\n",
    "    tower_2 = Conv1D(n0, kernel_size=3, padding='same', activation='relu')(tower_1)\n",
    "    U01_added = Add()([tower_2, tower_parallel_03, skipConnection2])\n",
    "\n",
    "    ## U Block 02\n",
    "    tower_3 = Conv1DTranspose(n0, kernel_size=3, padding='same', strides=2, activation='relu')(U01_added)\n",
    "    # parallel layer\n",
    "    tower_parallel_02 = Conv1DTranspose(n0, kernel_size=3, padding='same', strides=2, activation='relu')(U01_added) \n",
    "    tower_4 = Conv1D(n0, kernel_size=3, padding='same', activation='relu')(tower_3)\n",
    "    U02_added = Add()([tower_4, tower_parallel_02, skipConnection1])\n",
    "    \n",
    "    ## U Block 01\n",
    "    tower_5 = Conv1DTranspose(n0, kernel_size=3, padding='same', strides=2, activation='relu')(U02_added)\n",
    "    # parallel layer\n",
    "    tower_parallel_01 = Conv1DTranspose(n0, kernel_size=3, padding='same', strides=2, activation='relu')(U02_added)  \n",
    "    tower_6 = Conv1D(n0, kernel_size=3, padding='same', activation='relu')(tower_5)\n",
    "    U03_added = Add()([tower_6, tower_parallel_01, skipConnection0])\n",
    "    \n",
    "    # output layer\n",
    "    output_layer = Conv1D(2, kernel_size=3, padding='same', activation='linear')(U03_added)\n",
    "    flat = Flatten()(output_layer)\n",
    "    output = Dense(2, activation='linear')(flat)\n",
    "    \n",
    "    model = tf.keras.Model(input_shape, output)\n",
    "    #plot_model(model, to_file=img_path, show_layer_names=True, show_layer_activations=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, 1)      4           ['input_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 128, 1)       0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 64, 32)       128         ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 64, 32)       3104        ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 64, 32)       128         ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 64, 32)       0           ['conv1d_3[0][0]',               \n",
      "                                                                  'conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 32, 32)       3104        ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 32, 32)       3104        ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 32, 32)       3104        ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32)       0           ['conv1d_7[0][0]',               \n",
      "                                                                  'conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 16, 32)       3104        ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 16, 32)       3104        ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 16, 32)       3104        ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 16, 32)       0           ['conv1d_11[0][0]',              \n",
      "                                                                  'conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_transpose (Conv1DTransp  (None, 32, 32)      3104        ['add_2[0][0]']                  \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 32, 32)       3104        ['conv1d_transpose[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_transpose_1 (Conv1DTran  (None, 32, 32)      3104        ['add_2[0][0]']                  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 32, 32)       1056        ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 32, 32)       0           ['conv1d_12[0][0]',              \n",
      "                                                                  'conv1d_transpose_1[0][0]',     \n",
      "                                                                  'conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_transpose_2 (Conv1DTran  (None, 64, 32)      3104        ['add_3[0][0]']                  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 64, 32)       3104        ['conv1d_transpose_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_transpose_3 (Conv1DTran  (None, 64, 32)      3104        ['add_3[0][0]']                  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 64, 32)       1056        ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 64, 32)       0           ['conv1d_13[0][0]',              \n",
      "                                                                  'conv1d_transpose_3[0][0]',     \n",
      "                                                                  'conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_transpose_4 (Conv1DTran  (None, 128, 32)     3104        ['add_4[0][0]']                  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 128, 32)      3104        ['conv1d_transpose_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_transpose_5 (Conv1DTran  (None, 128, 32)     3104        ['add_4[0][0]']                  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 128, 32)      64          ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 128, 32)      0           ['conv1d_14[0][0]',              \n",
      "                                                                  'conv1d_transpose_5[0][0]',     \n",
      "                                                                  'conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 128, 2)       194         ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 256)          0           ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            514         ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52,808\n",
      "Trainable params: 52,806\n",
      "Non-trainable params: 2\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_convnet(128, 32)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation of a single polarization optical signal transmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transmitter parameters:\n",
    "paramTx = parameters()\n",
    "paramTx.M = 16                 # order of the modulation format\n",
    "paramTx.Rs = 32e9              # symbol rate [baud]\n",
    "paramTx.SpS = 4                # samples per symbol\n",
    "paramTx.Nbits = 40000          # total number of bits per polarization\n",
    "paramTx.pulse = \"rrc\"          # pulse shaping filter\n",
    "paramTx.Ntaps = 1024           # number of pulse shaping filter coefficients\n",
    "paramTx.alphaRRC = 0.5         # RRC rolloff\n",
    "paramTx.Pch_dBm = 0            # power of the optical signal [dBm]\n",
    "paramTx.Nch = 1                # number of WDM channels\n",
    "paramTx.Fc = 193.1e12          # central frequency of the optical spectrum\n",
    "paramTx.freqSpac = 37.5e9      # WDM grid spacing\n",
    "\n",
    "## Optical channel parameters:\n",
    "Ltotal = 100     # total link distance [km]\n",
    "alpha = 0        # fiber loss parameter [dB/km]\n",
    "D = 16           # fiber dispersion parameter [ps/nm/km]\n",
    "Fc = paramTx.Fc  # central optical frequency of the WDM spectrum [Hz]\n",
    "\n",
    "## Receiver parameters:\n",
    "\n",
    "# local oscillator (LO)\n",
    "FO = paramTx.Rs/2  # frequency offset\n",
    "lw = 0*200e3       # linewidth\n",
    "ϕ_lo = 0           # initial phase in rad\n",
    "#Plo_dBm = 12      # power in dBm\n",
    "\n",
    "# ADC sampling rate\n",
    "paramADC = parameters()\n",
    "paramADC.Rs = paramTx.Rs\n",
    "paramADC.SpS_in = paramTx.SpS\n",
    "paramADC.SpS_out = 4\n",
    "\n",
    "## General simulation parameters:\n",
    "chIndex = 0  # index of the channel to be demodulated\n",
    "plotPSD = True\n",
    "Fs = paramTx.Rs * paramTx.SpS  # simulation sampling rate\n",
    "Ts = 1 / Fs\n",
    "\n",
    "# photodiode parameters\n",
    "paramPD = parameters()\n",
    "paramPD.B  = 1.1*paramTx.Rs\n",
    "paramPD.Fs = Fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d09951a870401680d08f6f0682ac8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd43ae0799e400fa564310ba2861f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSPR = 6.00 dB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3caa2147ed4cee8794ae2298c0410f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSPR = 7.00 dB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6367ff4c444c68ac9ddfb2c45e73ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSPR = 8.00 dB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe1382b597d4103ad647812998d77e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSPR = 9.00 dB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab553188cb040d4a10ef546d0935670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSPR = 10.00 dB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d5b50b22aa48f194e1b8e110a4f1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSPR = 11.00 dB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42840c174b2e4f2780db408393147282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSPR = 12.00 dB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682743fb0d2a4c8d8a6e7e538e372730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSPR = 13.00 dB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d68efd8c492466aae2889587393ae64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSPR = 14.00 dB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6a5db6d0374433b29ce18b5dcf24cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSPR = 15.00 dB\n"
     ]
    }
   ],
   "source": [
    "N = 128 # number of input amplitude samples to the NN\n",
    "\n",
    "y_train_list = []\n",
    "X_train_list = []\n",
    "\n",
    "loPower = np.arange(6,16,1)\n",
    "\n",
    "for indPower, Plo_dBm in enumerate(tqdm(loPower)):\n",
    "\n",
    "    # generate optical signal signal\n",
    "    sigTx, symbTx_, paramTx = simpleWDMTx(paramTx)\n",
    "\n",
    "    # simulate linear signal propagation\n",
    "    sigCh = linFiberCh(sigTx, Ltotal, alpha, D, Fc, Fs)\n",
    "\n",
    "    symbTx = symbTx_[:, :, chIndex]\n",
    "    Plo = 10 ** (Plo_dBm / 10) * 1e-3  # power in W\n",
    "\n",
    "    # generate LO field\n",
    "    π = np.pi\n",
    "    t = np.arange(0, len(sigCh))*Ts\n",
    "    ϕ_pn_lo = phaseNoise(lw, len(sigCh), Ts)\n",
    "\n",
    "    sigLO = np.sqrt(Plo) * np.exp(-1j * (2 * π * FO * t + ϕ_lo + ϕ_pn_lo))\n",
    "\n",
    "    # Add LO to the received signal\n",
    "    sigRx = np.sqrt(Plo) + sigCh* np.exp(1j * (2 * π * FO * t + ϕ_lo + ϕ_pn_lo))\n",
    "    sfm   = sigRx.copy()\n",
    "\n",
    "    print('CSPR = %.2f dB'%(10*np.log10(signal_power(sigLO)/signal_power(sigCh))))\n",
    "\n",
    "    # simulate ideal direct-detection optical receiver\n",
    "    Ipd = photodiode(sigRx, paramPD)\n",
    "    Amp = np.sqrt(Ipd.real)\n",
    "    Amp = resample(Amp, paramADC).real\n",
    "\n",
    "    # resampling to ADC sampling rate\n",
    "    sigCh = resample(sigCh, paramADC)\n",
    "    sfm = resample(sfm, paramADC)\n",
    "    newFs = paramADC.SpS_out*paramTx.Rs\n",
    "\n",
    "    sfm = sfm/np.sqrt(signal_power(sfm))\n",
    "    \n",
    "    # Neural network training\n",
    "\n",
    "    #sigPhase = np.angle(sfm) # get signal phase samples (labels) (L,)\n",
    "    sigAmp = np.pad(Amp, (int(N/2), int(N/2)), 'constant') # get signal amplitude samples (L,)\n",
    "\n",
    "    # create set of input features\n",
    "    X_train = np.zeros((len(sfm), N)) #(L,N)\n",
    "\n",
    "    for indPhase in range(len(sfm)):\n",
    "        X_train[indPhase] = sigAmp[indPhase:N+indPhase]\n",
    "\n",
    "    # create set of phase labels\n",
    "    y_train = np.array([sfm.real, sfm.imag]).T\n",
    "\n",
    "    y_train_list.append(y_train)\n",
    "    X_train_list.append(X_train)\n",
    "\n",
    "y_train_final = np.concatenate(y_train_list, axis=0)\n",
    "X_train_final = np.concatenate(X_train_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 128) (400000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_final.shape, y_train_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permuta o conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = tf.range(start=0, limit=tf.shape(X_train_final)[0], dtype=tf.int32)\n",
    "idx = tf.random.shuffle(indices)\n",
    "\n",
    "x_data = tf.gather(X_train_final, idx)\n",
    "y_data = tf.gather(y_train_final, idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define o treinamento para rede MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4, input_shape=(N,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1094/1094 [==============================] - 5s 3ms/step - loss: 0.2064 - val_loss: 0.0656\n",
      "Epoch 2/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0517 - val_loss: 0.0482\n",
      "Epoch 3/200\n",
      "1094/1094 [==============================] - 3s 2ms/step - loss: 0.0383 - val_loss: 0.0289\n",
      "Epoch 4/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0281 - val_loss: 0.0273\n",
      "Epoch 5/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0270 - val_loss: 0.0267\n",
      "Epoch 6/200\n",
      "1094/1094 [==============================] - 3s 2ms/step - loss: 0.0262 - val_loss: 0.0258\n",
      "Epoch 7/200\n",
      "1094/1094 [==============================] - 3s 3ms/step - loss: 0.0245 - val_loss: 0.0095\n",
      "Epoch 8/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 9/200\n",
      "1094/1094 [==============================] - 3s 2ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 10/200\n",
      "1094/1094 [==============================] - 3s 2ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 11/200\n",
      "1094/1094 [==============================] - 3s 2ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 12/200\n",
      "1094/1094 [==============================] - 3s 2ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 13/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 14/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 15/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 16/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 17/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 18/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 19/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 20/200\n",
      "1094/1094 [==============================] - 3s 2ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 21/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 22/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 23/200\n",
      "1094/1094 [==============================] - 2s 2ms/step - loss: 0.0050 - val_loss: 0.0047\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(x_data, y_data, epochs=200, callbacks=[stop], validation_split=0.3, batch_size=256)\n",
    "model.save('C:/Users/silas/Documents/PIVIC-PIBIC-Comunicacoes-Opticas/models/NN_models/'+'testModel_SpS_'+str(paramTx.SpS)+'_CSPR_DataPermuted', save_format='h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define o treinamento para a DeepTCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepTCN(\n",
    "    y=y_data,\n",
    "    x=x_data,\n",
    "    forecast_period=2,\n",
    "    lookback_period=2,\n",
    "    quantiles=[0.001, 0.1, 0.5, 0.9, 0.999],\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    dilation_rates=[4],\n",
    "    loss='mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4375/4375 [==============================] - 37s 6ms/step - loss: 0.0373 - val_loss: 0.0236\n",
      "Epoch 2/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0217 - val_loss: 0.0227\n",
      "Epoch 3/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0203 - val_loss: 0.0198\n",
      "Epoch 4/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0195 - val_loss: 0.0178\n",
      "Epoch 5/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0191 - val_loss: 0.0196\n",
      "Epoch 6/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 7/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0184 - val_loss: 0.0192\n",
      "Epoch 8/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0180 - val_loss: 0.0170\n",
      "Epoch 9/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0178 - val_loss: 0.0174\n",
      "Epoch 10/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0176 - val_loss: 0.0162\n",
      "Epoch 11/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0173 - val_loss: 0.0162\n",
      "Epoch 12/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0168 - val_loss: 0.0163\n",
      "Epoch 13/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0165 - val_loss: 0.0147\n",
      "Epoch 14/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0163 - val_loss: 0.0172\n",
      "Epoch 15/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0161 - val_loss: 0.0154\n",
      "Epoch 16/200\n",
      "4375/4375 [==============================] - 24s 6ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 17/200\n",
      "4375/4375 [==============================] - 24s 6ms/step - loss: 0.0154 - val_loss: 0.0152\n",
      "Epoch 18/200\n",
      "4375/4375 [==============================] - 24s 6ms/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 19/200\n",
      "4375/4375 [==============================] - 24s 6ms/step - loss: 0.0148 - val_loss: 0.0144\n",
      "Epoch 20/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0145 - val_loss: 0.0151\n",
      "Epoch 21/200\n",
      "4375/4375 [==============================] - 24s 6ms/step - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 22/200\n",
      "4375/4375 [==============================] - 24s 6ms/step - loss: 0.0139 - val_loss: 0.0132\n",
      "Epoch 23/200\n",
      "4375/4375 [==============================] - 24s 6ms/step - loss: 0.0136 - val_loss: 0.0128\n",
      "Epoch 24/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0135 - val_loss: 0.0139\n",
      "Epoch 25/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 26/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0131 - val_loss: 0.0132\n",
      "Epoch 27/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 28/200\n",
      "4375/4375 [==============================] - 24s 6ms/step - loss: 0.0128 - val_loss: 0.0116\n",
      "Epoch 29/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0126 - val_loss: 0.0114\n",
      "Epoch 30/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0124 - val_loss: 0.0133\n",
      "Epoch 31/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 32/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 33/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 34/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 35/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 36/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 37/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 38/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 39/200\n",
      "4375/4375 [==============================] - 25s 6ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 40/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 41/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 42/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 43/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0108 - val_loss: 0.0147\n",
      "Epoch 44/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 45/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 46/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0106 - val_loss: 0.0086\n",
      "Epoch 47/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 48/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 49/200\n",
      "4375/4375 [==============================] - 27s 6ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 50/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 51/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 52/200\n",
      "4375/4375 [==============================] - 26s 6ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 53/200\n",
      "4375/4375 [==============================] - 27s 6ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 54/200\n",
      "4375/4375 [==============================] - 27s 6ms/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 55/200\n",
      "4375/4375 [==============================] - 30s 7ms/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 56/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 57/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 58/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 59/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 60/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 61/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 62/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 63/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0100 - val_loss: 0.0082\n",
      "Epoch 64/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 65/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 66/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0100 - val_loss: 0.0080\n",
      "Epoch 67/200\n",
      "4375/4375 [==============================] - 27s 6ms/step - loss: 0.0100 - val_loss: 0.0081\n",
      "Epoch 68/200\n",
      "4375/4375 [==============================] - 27s 6ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 69/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 70/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0100 - val_loss: 0.0080\n",
      "Epoch 71/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 72/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 73/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 74/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 75/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 76/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 77/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 78/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 79/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 80/200\n",
      "4375/4375 [==============================] - 30s 7ms/step - loss: 0.0099 - val_loss: 0.0091\n",
      "Epoch 81/200\n",
      "4375/4375 [==============================] - 30s 7ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 82/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 83/200\n",
      "4375/4375 [==============================] - 27s 6ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 84/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 85/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 86/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 87/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0099 - val_loss: 0.0091\n",
      "Epoch 88/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0099 - val_loss: 0.0091\n",
      "Epoch 89/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 90/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 91/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 92/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0098 - val_loss: 0.0078\n",
      "Epoch 93/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 94/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 95/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 96/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 97/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0098 - val_loss: 0.0077\n",
      "Epoch 98/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0099 - val_loss: 0.0081\n",
      "Epoch 99/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0098 - val_loss: 0.0075\n",
      "Epoch 100/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 101/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0098 - val_loss: 0.0077\n",
      "Epoch 102/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 103/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 104/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 105/200\n",
      "4375/4375 [==============================] - 28s 6ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 106/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 107/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 108/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 109/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 110/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 111/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 112/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 113/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0098 - val_loss: 0.0076\n",
      "Epoch 114/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0097 - val_loss: 0.0087\n",
      "Epoch 115/200\n",
      "4375/4375 [==============================] - 29s 7ms/step - loss: 0.0097 - val_loss: 0.0076\n",
      "Epoch 116/200\n",
      "4375/4375 [==============================] - 31s 7ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 117/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 118/200\n",
      "4375/4375 [==============================] - 31s 7ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 119/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0098 - val_loss: 0.0077\n",
      "Epoch 120/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 121/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 122/200\n",
      "4375/4375 [==============================] - 33s 7ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 123/200\n",
      "4375/4375 [==============================] - 33s 7ms/step - loss: 0.0097 - val_loss: 0.0076\n",
      "Epoch 124/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 125/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0097 - val_loss: 0.0072\n",
      "Epoch 126/200\n",
      "4375/4375 [==============================] - 33s 7ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 127/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0097 - val_loss: 0.0073\n",
      "Epoch 128/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 129/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0097 - val_loss: 0.0073\n",
      "Epoch 130/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 131/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 132/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 133/200\n",
      "4375/4375 [==============================] - 34s 8ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 134/200\n",
      "4375/4375 [==============================] - 34s 8ms/step - loss: 0.0097 - val_loss: 0.0087\n",
      "Epoch 135/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0097 - val_loss: 0.0077\n",
      "Epoch 136/200\n",
      "4375/4375 [==============================] - 31s 7ms/step - loss: 0.0097 - val_loss: 0.0079\n",
      "Epoch 137/200\n",
      "4375/4375 [==============================] - 31s 7ms/step - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 138/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 139/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 140/200\n",
      "4375/4375 [==============================] - 33s 7ms/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 141/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 142/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 143/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0097 - val_loss: 0.0077\n",
      "Epoch 144/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0097 - val_loss: 0.0073\n",
      "Epoch 145/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0096 - val_loss: 0.0077\n",
      "Epoch 146/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 147/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 148/200\n",
      "4375/4375 [==============================] - 33s 7ms/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 149/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0096 - val_loss: 0.0075\n",
      "Epoch 150/200\n",
      "4375/4375 [==============================] - 33s 7ms/step - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 151/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 152/200\n",
      "4375/4375 [==============================] - 33s 7ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 153/200\n",
      "4375/4375 [==============================] - 33s 7ms/step - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 154/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 155/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 156/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0096 - val_loss: 0.0077\n",
      "Epoch 157/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0096 - val_loss: 0.0079\n",
      "Epoch 158/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 159/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 160/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0097 - val_loss: 0.0077\n",
      "Epoch 161/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 162/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 163/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 164/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0097 - val_loss: 0.0076\n",
      "Epoch 165/200\n",
      "4375/4375 [==============================] - 34s 8ms/step - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 166/200\n",
      "4375/4375 [==============================] - 34s 8ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 167/200\n",
      "4375/4375 [==============================] - 34s 8ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "Epoch 168/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0097 - val_loss: 0.0073\n",
      "Epoch 169/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 170/200\n",
      "4375/4375 [==============================] - 34s 8ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 171/200\n",
      "4375/4375 [==============================] - 34s 8ms/step - loss: 0.0096 - val_loss: 0.0073\n",
      "Epoch 172/200\n",
      "4375/4375 [==============================] - 34s 8ms/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 173/200\n",
      "4375/4375 [==============================] - 1250s 286ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 174/200\n",
      "4375/4375 [==============================] - 33s 8ms/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 175/200\n",
      "4375/4375 [==============================] - 32s 7ms/step - loss: 0.0095 - val_loss: 0.0084\n",
      "Epoch 176/200\n",
      "4375/4375 [==============================] - 34s 8ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 177/200\n",
      "4375/4375 [==============================] - 35s 8ms/step - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 178/200\n",
      "4375/4375 [==============================] - 36s 8ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 179/200\n",
      "4375/4375 [==============================] - 34s 8ms/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 180/200\n",
      "4375/4375 [==============================] - 34s 8ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 181/200\n",
      "4375/4375 [==============================] - 35s 8ms/step - loss: 0.0096 - val_loss: 0.0086\n",
      "Epoch 182/200\n",
      "4375/4375 [==============================] - 36s 8ms/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 183/200\n",
      "4375/4375 [==============================] - 35s 8ms/step - loss: 0.0096 - val_loss: 0.0079\n",
      "Epoch 184/200\n",
      "4375/4375 [==============================] - 35s 8ms/step - loss: 0.0096 - val_loss: 0.0073\n",
      "Epoch 185/200\n",
      "4375/4375 [==============================] - 36s 8ms/step - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 186/200\n",
      "4375/4375 [==============================] - 37s 8ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 187/200\n",
      "4375/4375 [==============================] - 37s 8ms/step - loss: 0.0096 - val_loss: 0.0078\n",
      "Epoch 188/200\n",
      "4375/4375 [==============================] - 37s 9ms/step - loss: 0.0096 - val_loss: 0.0077\n",
      "Epoch 189/200\n",
      "4375/4375 [==============================] - 37s 9ms/step - loss: 0.0095 - val_loss: 0.0078\n",
      "Epoch 190/200\n",
      "4375/4375 [==============================] - 38s 9ms/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 191/200\n",
      "4375/4375 [==============================] - 38s 9ms/step - loss: 0.0096 - val_loss: 0.0078\n",
      "Epoch 192/200\n",
      "4375/4375 [==============================] - 38s 9ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 193/200\n",
      "4375/4375 [==============================] - 38s 9ms/step - loss: 0.0096 - val_loss: 0.0078\n",
      "Epoch 194/200\n",
      "4375/4375 [==============================] - 38s 9ms/step - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 195/200\n",
      "4375/4375 [==============================] - 36s 8ms/step - loss: 0.0095 - val_loss: 0.0087\n",
      "Epoch 196/200\n",
      "4375/4375 [==============================] - 37s 8ms/step - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 197/200\n",
      "4375/4375 [==============================] - 37s 8ms/step - loss: 0.0095 - val_loss: 0.0073\n",
      "Epoch 198/200\n",
      "4375/4375 [==============================] - 37s 8ms/step - loss: 0.0095 - val_loss: 0.0072\n",
      "Epoch 199/200\n",
      "4375/4375 [==============================] - 37s 8ms/step - loss: 0.0096 - val_loss: 0.0077\n",
      "Epoch 200/200\n",
      "4375/4375 [==============================] - 37s 9ms/step - loss: 0.0096 - val_loss: 0.0075\n"
     ]
    }
   ],
   "source": [
    "path = r'C:/Users/silas/Documents/PIVIC-PIBIC-Comunicacoes-Opticas/models/deep_tcn_tensorflow/'\n",
    "\n",
    "model.fit(\n",
    "    learning_rate=0.001,\n",
    "    batch_size=64,\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "model.saveModel(path+'testModel_SpS_'+str(paramTx.SpS)+'_CSPR_DataPermuted')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define o treinamento para rede convolucional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1094/1094 [==============================] - 187s 167ms/step - loss: 0.0250 - val_loss: 0.0064\n",
      "Epoch 2/200\n",
      "1094/1094 [==============================] - 175s 160ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 3/200\n",
      "1094/1094 [==============================] - 175s 160ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 4/200\n",
      "1094/1094 [==============================] - 177s 162ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 5/200\n",
      "1094/1094 [==============================] - 174s 159ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 6/200\n",
      "1094/1094 [==============================] - 163s 149ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 7/200\n",
      "1094/1094 [==============================] - 169s 155ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 8/200\n",
      "1094/1094 [==============================] - 177s 162ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 9/200\n",
      "1094/1094 [==============================] - 174s 159ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 10/200\n",
      "1094/1094 [==============================] - 175s 160ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 11/200\n",
      "1094/1094 [==============================] - 173s 158ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 12/200\n",
      "1094/1094 [==============================] - 174s 159ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 13/200\n",
      "1094/1094 [==============================] - 173s 158ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 14/200\n",
      "1094/1094 [==============================] - 164s 150ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 15/200\n",
      "1094/1094 [==============================] - 160s 146ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 16/200\n",
      "1094/1094 [==============================] - 158s 145ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 17/200\n",
      "1094/1094 [==============================] - 158s 144ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 18/200\n",
      "1094/1094 [==============================] - 157s 144ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 19/200\n",
      "1094/1094 [==============================] - 175s 160ms/step - loss: 0.0039 - val_loss: 0.0039\n"
     ]
    }
   ],
   "source": [
    "path = 'C:/Users/silas/Documents/PIVIC-PIBIC-Comunicacoes-Opticas/models/Conv_models/'\n",
    "n0 = 32\n",
    "\n",
    "# define neural network model\n",
    "stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model = create_convnet(N, n0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "model.fit(x_data, y_data, epochs=200, callbacks=[stop], validation_split=0.3, batch_size=256)\n",
    "# model.summary()\n",
    "\n",
    "model.save(path+'testModel_SpS_'+str(paramTx.SpS)+'_CSPR_DataPermuted', save_format='h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
